{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "01a1d864",
      "metadata": {
        "id": "01a1d864"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install python3.9 python3.9-dev python3.9-venv -y\n",
        "# 检查已安装的Python版本\n",
        "!ls /usr/bin/python*\n",
        "\n",
        "# 更新alternatives配置\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1\n",
        "\n",
        "# 手动选择默认版本（选python3.9对应的编号）\n",
        "!sudo update-alternatives --config python3\n",
        "!python3 --version  # 应显示 Python 3.9.x\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.9\n",
        "!python3 -m pip install --upgrade pip\n",
        "!pip install git+https://github.com/d2l-ai/d2l-zh@release\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.9/dist-packages')\n",
        "!pip show d2l\n",
        "print(sys.path)  # 查看所有模块搜索路径\n",
        "# 手动尝试导入\n",
        "try:\n",
        "    import d2l\n",
        "    print(\"成功导入！\")\n",
        "except ImportError:\n",
        "    print(\"导入失败\")"
      ],
      "metadata": {
        "id": "Kg8h-e2Z2_UT",
        "outputId": "fed2b28d-85b5-42b6-dee7-bcac51247387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Kg8h-e2Z2_UT",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,742 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,246 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,295 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,984 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,021 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,553 kB]\n",
            "Fetched 21.2 MB in 4s (4,930 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "39 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.9 libpython3.9-dev libpython3.9-minimal libpython3.9-stdlib\n",
            "  python3.9-distutils python3.9-lib2to3 python3.9-minimal\n",
            "Suggested packages:\n",
            "  binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.9 libpython3.9-dev libpython3.9-minimal libpython3.9-stdlib\n",
            "  python3.9 python3.9-dev python3.9-distutils python3.9-lib2to3\n",
            "  python3.9-minimal python3.9-venv\n",
            "0 upgraded, 10 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 14.9 MB of archives.\n",
            "After this operation, 49.5 MB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-minimal amd64 3.9.23-1+jammy1 [837 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-minimal amd64 3.9.23-1+jammy1 [2,075 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-stdlib amd64 3.9.23-1+jammy1 [1,842 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9 amd64 3.9.23-1+jammy1 [1,904 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-dev amd64 3.9.23-1+jammy1 [4,630 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9 amd64 3.9.23-1+jammy1 [93.1 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-dev amd64 3.9.23-1+jammy1 [500 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-lib2to3 all 3.9.23-1+jammy1 [127 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-distutils all 3.9.23-1+jammy1 [193 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-venv amd64 3.9.23-1+jammy1 [2,650 kB]\n",
            "Fetched 14.9 MB in 1min 10s (213 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 10.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.9-minimal:amd64.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.9-minimal_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-minimal:amd64 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-minimal.\n",
            "Preparing to unpack .../1-python3.9-minimal_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9-minimal (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.9-stdlib:amd64.\n",
            "Preparing to unpack .../2-libpython3.9-stdlib_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-stdlib:amd64 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.9:amd64.\n",
            "Preparing to unpack .../3-libpython3.9_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9:amd64 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.9-dev:amd64.\n",
            "Preparing to unpack .../4-libpython3.9-dev_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-dev:amd64 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9.\n",
            "Preparing to unpack .../5-python3.9_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-dev.\n",
            "Preparing to unpack .../6-python3.9-dev_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9-dev (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-lib2to3.\n",
            "Preparing to unpack .../7-python3.9-lib2to3_3.9.23-1+jammy1_all.deb ...\n",
            "Unpacking python3.9-lib2to3 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-distutils.\n",
            "Preparing to unpack .../8-python3.9-distutils_3.9.23-1+jammy1_all.deb ...\n",
            "Unpacking python3.9-distutils (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-venv.\n",
            "Preparing to unpack .../9-python3.9-venv_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9-venv (3.9.23-1+jammy1) ...\n",
            "Setting up libpython3.9-minimal:amd64 (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-lib2to3 (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-distutils (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-minimal (3.9.23-1+jammy1) ...\n",
            "Setting up libpython3.9-stdlib:amd64 (3.9.23-1+jammy1) ...\n",
            "Setting up libpython3.9:amd64 (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9 (3.9.23-1+jammy1) ...\n",
            "Setting up libpython3.9-dev:amd64 (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-dev (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-venv (3.9.23-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "/usr/bin/python3\t    /usr/bin/python3.11-config\n",
            "/usr/bin/python3.10\t    /usr/bin/python3.9\n",
            "/usr/bin/python3.10-config  /usr/bin/python3.9-config\n",
            "/usr/bin/python3.11\t    /usr/bin/python3-config\n",
            "There are 3 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.11   2         auto mode\n",
            "  1            /usr/bin/python3.10   1         manual mode\n",
            "  2            /usr/bin/python3.11   2         manual mode\n",
            "  3            /usr/bin/python3.9    1         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 3\n",
            "update-alternatives: using /usr/bin/python3.9 to provide /usr/bin/python3 (python3) in manual mode\n",
            "Python 3.9.23\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pip]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pip-25.1.1 setuptools-80.9.0 wheel-0.45.1\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (25.1.1)\n",
            "\u001b[33mWARNING: Package(s) not found: d2l\u001b[0m\u001b[33m\n",
            "\u001b[0m['/content', '/env/python', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.11/dist-packages/IPython/extensions', '/usr/local/lib/python3.11/dist-packages/setuptools/_vendor', '/root/.ipython', '/usr/local/lib/python3.9/dist-packages']\n",
            "导入失败\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b25e281c",
      "metadata": {
        "id": "b25e281c",
        "outputId": "fad5a681-c920-483f-f7a4-2a9866013df3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/d2l-ai/d2l-zh@release\n",
            "  Cloning https://github.com/d2l-ai/d2l-zh (to revision release) to /tmp/pip-req-build-4ezu5q8e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/d2l-ai/d2l-zh /tmp/pip-req-build-4ezu5q8e\n",
            "  Running command git checkout -b release --track origin/release\n",
            "  Switched to a new branch 'release'\n",
            "  Branch 'release' set up to track remote branch 'release' from 'origin'.\n",
            "  Resolved https://github.com/d2l-ai/d2l-zh to commit 843d3d41dca48d8df65f4b324dd171d8bfe9c067\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jupyter==1.0.0 (from d2l==2.0.0)\n",
            "  Using cached jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "Collecting numpy==1.21.5 (from d2l==2.0.0)\n",
            "  Downloading numpy-1.21.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting matplotlib==3.5.1 (from d2l==2.0.0)\n",
            "  Downloading matplotlib-3.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting requests==2.25.1 (from d2l==2.0.0)\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pandas==1.2.4 (from d2l==2.0.0)\n",
            "  Downloading pandas-1.2.4-cp39-cp39-manylinux1_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting notebook (from jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading notebook-7.4.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting qtconsole (from jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading qtconsole-5.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting jupyter-console (from jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting nbconvert (from jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting ipykernel (from jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ipywidgets (from jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib==3.5.1->d2l==2.0.0)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib==3.5.1->d2l==2.0.0)\n",
            "  Downloading fonttools-4.58.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (106 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib==3.5.1->d2l==2.0.0)\n",
            "  Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting packaging>=20.0 (from matplotlib==3.5.1->d2l==2.0.0)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pillow>=6.2.0 (from matplotlib==3.5.1->d2l==2.0.0)\n",
            "  Downloading pillow-11.2.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib==3.5.1->d2l==2.0.0) (2.4.7)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib==3.5.1->d2l==2.0.0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2017.3 (from pandas==1.2.4->d2l==2.0.0)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting chardet<5,>=3.0.2 (from requests==2.25.1->d2l==2.0.0)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting idna<3,>=2.5 (from requests==2.25.1->d2l==2.0.0)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1 (from requests==2.25.1->d2l==2.0.0)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests==2.25.1->d2l==2.0.0)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.1->d2l==2.0.0) (1.16.0)\n",
            "Collecting comm>=0.1.1 (from ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting debugpy>=1.6.5 (from ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading debugpy-1.8.14-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting ipython>=7.23.1 (from ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading ipython-8.18.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyter_core-5.8.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting matplotlib-inline>=0.1 (from ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting nest-asyncio (from ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting psutil (from ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting pyzmq>=24 (from ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading pyzmq-26.4.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting tornado>=6.1 (from ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading tornado-6.5.1-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting traitlets>=5.4.0 (from ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting decorator (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting prompt-toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading prompt_toolkit-3.0.51-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pygments>=2.4.0 (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting stack-data (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting typing-extensions (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting exceptiongroup (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting wcwidth (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting importlib-metadata>=4.8.3 (from jupyter-client>=6.1.12->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting platformdirs>=2.5 (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading platformdirs-4.3.8-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting beautifulsoup4 (from nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting defusedxml (from nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting jinja2>=3.0 (from nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jupyterlab-pygments (from nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/lib/python3/dist-packages (from nbconvert->jupyter==1.0.0->d2l==2.0.0) (2.0.1)\n",
            "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading mistune-3.1.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting nbclient>=0.5.0 (from nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting nbformat>=5.7 (from nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting fastjsonschema>=2.15 (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting jsonschema>=2.6 (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading rpds_py-0.25.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyter_server-2.16.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyterlab<4.5,>=4.4.3 (from notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyterlab-4.4.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting notebook-shim<0.3,>=0.2 (from notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting anyio>=3.1.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab<4.5,>=4.4.3->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting httpx>=0.25.0 (from jupyterlab<4.5,>=4.4.3->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab<4.5,>=4.4.3->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.9/dist-packages (from jupyterlab<4.5,>=4.4.3->notebook->jupyter==1.0.0->d2l==2.0.0) (80.9.0)\n",
            "Collecting tomli>=1.2.2 (from jupyterlab<4.5,>=4.4.3->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "INFO: pip is looking at multiple versions of jupyterlab-server to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyterlab_server-2.27.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading jupyterlab_server-2.27.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting notebook (from jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading notebook-7.4.2-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: pip is still looking at multiple versions of jupyterlab-server to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading notebook-7.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading notebook-7.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading notebook-7.3.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jupyterlab<4.4,>=4.3.6 (from notebook->jupyter==1.0.0->d2l==2.0.0)\n",
            "  Downloading jupyterlab-4.3.7-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting notebook (from jupyter==1.0.0->d2l==2.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e211967",
      "metadata": {
        "origin_pos": 0,
        "id": "3e211967"
      },
      "source": [
        "# 线性回归的简洁实现\n",
        ":label:`sec_linear_concise`\n",
        "\n",
        "在过去的几年里，出于对深度学习强烈的兴趣，\n",
        "许多公司、学者和业余爱好者开发了各种成熟的开源框架。\n",
        "这些框架可以自动化基于梯度的学习算法中重复性的工作。\n",
        "在 :numref:`sec_linear_scratch`中，我们只运用了：\n",
        "（1）通过张量来进行数据存储和线性代数；\n",
        "（2）通过自动微分来计算梯度。\n",
        "实际上，由于数据迭代器、损失函数、优化器和神经网络层很常用，\n",
        "现代深度学习库也为我们实现了这些组件。\n",
        "\n",
        "本节将介绍如何(**通过使用深度学习框架来简洁地实现**)\n",
        " :numref:`sec_linear_scratch`中的(**线性回归模型**)。\n",
        "\n",
        "## 生成数据集\n",
        "\n",
        "与 :numref:`sec_linear_scratch`中类似，我们首先[**生成数据集**]。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5c88734d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:01:52.522009Z",
          "iopub.status.busy": "2023-08-18T07:01:52.521295Z",
          "iopub.status.idle": "2023-08-18T07:01:54.610713Z",
          "shell.execute_reply": "2023-08-18T07:01:54.609677Z"
        },
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ],
        "id": "5c88734d",
        "outputId": "4bd6a34f-d928-4ba1-cb56-baab2e45143e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'd2l'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3358149943>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0md2l\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'd2l'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils import data\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c26b741f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:01:54.616404Z",
          "iopub.status.busy": "2023-08-18T07:01:54.615685Z",
          "iopub.status.idle": "2023-08-18T07:01:54.643472Z",
          "shell.execute_reply": "2023-08-18T07:01:54.642512Z"
        },
        "origin_pos": 5,
        "tab": [
          "pytorch"
        ],
        "id": "c26b741f"
      },
      "outputs": [],
      "source": [
        "true_w = torch.tensor([2, -3.4])\n",
        "true_b = 4.2\n",
        "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6fd8db7",
      "metadata": {
        "origin_pos": 6,
        "id": "e6fd8db7"
      },
      "source": [
        "## 读取数据集\n",
        "\n",
        "我们可以[**调用框架中现有的API来读取数据**]。\n",
        "我们将`features`和`labels`作为API的参数传递，并通过数据迭代器指定`batch_size`。\n",
        "此外，布尔值`is_train`表示是否希望数据迭代器对象在每个迭代周期内打乱数据。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "955f5cc0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:01:54.648232Z",
          "iopub.status.busy": "2023-08-18T07:01:54.647744Z",
          "iopub.status.idle": "2023-08-18T07:01:54.653335Z",
          "shell.execute_reply": "2023-08-18T07:01:54.652317Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "955f5cc0"
      },
      "outputs": [],
      "source": [
        "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
        "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
        "    dataset = data.TensorDataset(*data_arrays)\n",
        "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c041eafa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:01:54.657592Z",
          "iopub.status.busy": "2023-08-18T07:01:54.656999Z",
          "iopub.status.idle": "2023-08-18T07:01:54.661787Z",
          "shell.execute_reply": "2023-08-18T07:01:54.660785Z"
        },
        "origin_pos": 11,
        "tab": [
          "pytorch"
        ],
        "id": "c041eafa"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "data_iter = load_array((features, labels), batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "503e6815",
      "metadata": {
        "origin_pos": 12,
        "id": "503e6815"
      },
      "source": [
        "使用`data_iter`的方式与我们在 :numref:`sec_linear_scratch`中使用`data_iter`函数的方式相同。为了验证是否正常工作，让我们读取并打印第一个小批量样本。\n",
        "与 :numref:`sec_linear_scratch`不同，这里我们使用`iter`构造Python迭代器，并使用`next`从迭代器中获取第一项。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c6919b8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:01:54.665574Z",
          "iopub.status.busy": "2023-08-18T07:01:54.664999Z",
          "iopub.status.idle": "2023-08-18T07:01:54.673523Z",
          "shell.execute_reply": "2023-08-18T07:01:54.672688Z"
        },
        "origin_pos": 13,
        "tab": [
          "pytorch"
        ],
        "id": "7c6919b8",
        "outputId": "e8c3a137-8a96-4c0f-f3d5-91b19f02fa9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[-1.3116, -0.3062],\n",
              "         [-1.5653,  0.4830],\n",
              "         [-0.8893, -0.9466],\n",
              "         [-1.2417,  1.6891],\n",
              "         [-0.7148,  0.1376],\n",
              "         [-0.2162, -0.6122],\n",
              "         [ 2.4048, -0.3211],\n",
              "         [-0.1516,  0.4997],\n",
              "         [ 1.5298, -0.2291],\n",
              "         [ 1.3895,  1.2602]]),\n",
              " tensor([[ 2.6073],\n",
              "         [-0.5787],\n",
              "         [ 5.6339],\n",
              "         [-4.0211],\n",
              "         [ 2.3117],\n",
              "         [ 5.8492],\n",
              "         [10.0926],\n",
              "         [ 2.1932],\n",
              "         [ 8.0441],\n",
              "         [ 2.6943]])]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(data_iter))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f57af75",
      "metadata": {
        "origin_pos": 14,
        "id": "4f57af75"
      },
      "source": [
        "## 定义模型\n",
        "\n",
        "当我们在 :numref:`sec_linear_scratch`中实现线性回归时，\n",
        "我们明确定义了模型参数变量，并编写了计算的代码，这样通过基本的线性代数运算得到输出。\n",
        "但是，如果模型变得更加复杂，且当我们几乎每天都需要实现模型时，自然会想简化这个过程。\n",
        "这种情况类似于为自己的博客从零开始编写网页。\n",
        "做一两次是有益的，但如果每个新博客就需要工程师花一个月的时间重新开始编写网页，那并不高效。\n",
        "\n",
        "对于标准深度学习模型，我们可以[**使用框架的预定义好的层**]。这使我们只需关注使用哪些层来构造模型，而不必关注层的实现细节。\n",
        "我们首先定义一个模型变量`net`，它是一个`Sequential`类的实例。\n",
        "`Sequential`类将多个层串联在一起。\n",
        "当给定输入数据时，`Sequential`实例将数据传入到第一层，\n",
        "然后将第一层的输出作为第二层的输入，以此类推。\n",
        "在下面的例子中，我们的模型只包含一个层，因此实际上不需要`Sequential`。\n",
        "但是由于以后几乎所有的模型都是多层的，在这里使用`Sequential`会让你熟悉“标准的流水线”。\n",
        "\n",
        "回顾 :numref:`fig_single_neuron`中的单层网络架构，\n",
        "这一单层被称为*全连接层*（fully-connected layer），\n",
        "因为它的每一个输入都通过矩阵-向量乘法得到它的每个输出。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b7cb683",
      "metadata": {
        "origin_pos": 16,
        "tab": [
          "pytorch"
        ],
        "id": "2b7cb683"
      },
      "source": [
        "在PyTorch中，全连接层在`Linear`类中定义。\n",
        "值得注意的是，我们将两个参数传递到`nn.Linear`中。\n",
        "第一个指定输入特征形状，即2，第二个指定输出特征形状，输出特征形状为单个标量，因此为1。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c54a1a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:01:54.677177Z",
          "iopub.status.busy": "2023-08-18T07:01:54.676580Z",
          "iopub.status.idle": "2023-08-18T07:01:54.680914Z",
          "shell.execute_reply": "2023-08-18T07:01:54.680130Z"
        },
        "origin_pos": 20,
        "tab": [
          "pytorch"
        ],
        "id": "85c54a1a"
      },
      "outputs": [],
      "source": [
        "# nn是神经网络的缩写\n",
        "from torch import nn\n",
        "\n",
        "net = nn.Sequential(nn.Linear(2, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc18b2c1",
      "metadata": {
        "origin_pos": 23,
        "id": "fc18b2c1"
      },
      "source": [
        "## (**初始化模型参数**)\n",
        "\n",
        "在使用`net`之前，我们需要初始化模型参数。\n",
        "如在线性回归模型中的权重和偏置。\n",
        "深度学习框架通常有预定义的方法来初始化参数。\n",
        "在这里，我们指定每个权重参数应该从均值为0、标准差为0.01的正态分布中随机采样，\n",
        "偏置参数将初始化为零。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7452e3b",
      "metadata": {
        "origin_pos": 25,
        "tab": [
          "pytorch"
        ],
        "id": "f7452e3b"
      },
      "source": [
        "正如我们在构造`nn.Linear`时指定输入和输出尺寸一样，\n",
        "现在我们能直接访问参数以设定它们的初始值。\n",
        "我们通过`net[0]`选择网络中的第一个图层，\n",
        "然后使用`weight.data`和`bias.data`方法访问参数。\n",
        "我们还可以使用替换方法`normal_`和`fill_`来重写参数值。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31716c55",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:01:54.684561Z",
          "iopub.status.busy": "2023-08-18T07:01:54.684036Z",
          "iopub.status.idle": "2023-08-18T07:01:54.690673Z",
          "shell.execute_reply": "2023-08-18T07:01:54.689754Z"
        },
        "origin_pos": 29,
        "tab": [
          "pytorch"
        ],
        "id": "31716c55",
        "outputId": "4093292d-bc1d-493f-861d-3d94251137e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net[0].weight.data.normal_(0, 0.01)\n",
        "net[0].bias.data.fill_(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94568f78",
      "metadata": {
        "origin_pos": 33,
        "tab": [
          "pytorch"
        ],
        "id": "94568f78"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9592f9a",
      "metadata": {
        "origin_pos": 35,
        "id": "e9592f9a"
      },
      "source": [
        "## 定义损失函数\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a431ee3",
      "metadata": {
        "origin_pos": 37,
        "tab": [
          "pytorch"
        ],
        "id": "9a431ee3"
      },
      "source": [
        "[**计算均方误差使用的是`MSELoss`类，也称为平方$L_2$范数**]。\n",
        "默认情况下，它返回所有样本损失的平均值。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19a417ac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:01:54.695575Z",
          "iopub.status.busy": "2023-08-18T07:01:54.694922Z",
          "iopub.status.idle": "2023-08-18T07:01:54.699373Z",
          "shell.execute_reply": "2023-08-18T07:01:54.698348Z"
        },
        "origin_pos": 41,
        "tab": [
          "pytorch"
        ],
        "id": "19a417ac"
      },
      "outputs": [],
      "source": [
        "loss = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30dbe343",
      "metadata": {
        "origin_pos": 44,
        "id": "30dbe343"
      },
      "source": [
        "## 定义优化算法\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2663da90",
      "metadata": {
        "origin_pos": 46,
        "tab": [
          "pytorch"
        ],
        "id": "2663da90"
      },
      "source": [
        "小批量随机梯度下降算法是一种优化神经网络的标准工具，\n",
        "PyTorch在`optim`模块中实现了该算法的许多变种。\n",
        "当我们(**实例化一个`SGD`实例**)时，我们要指定优化的参数\n",
        "（可通过`net.parameters()`从我们的模型中获得）以及优化算法所需的超参数字典。\n",
        "小批量随机梯度下降只需要设置`lr`值，这里设置为0.03。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ae0989f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:01:54.703905Z",
          "iopub.status.busy": "2023-08-18T07:01:54.703368Z",
          "iopub.status.idle": "2023-08-18T07:01:54.708081Z",
          "shell.execute_reply": "2023-08-18T07:01:54.706987Z"
        },
        "origin_pos": 50,
        "tab": [
          "pytorch"
        ],
        "id": "1ae0989f"
      },
      "outputs": [],
      "source": [
        "trainer = torch.optim.SGD(net.parameters(), lr=0.03)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "004056f1",
      "metadata": {
        "origin_pos": 53,
        "id": "004056f1"
      },
      "source": [
        "## 训练\n",
        "\n",
        "通过深度学习框架的高级API来实现我们的模型只需要相对较少的代码。\n",
        "我们不必单独分配参数、不必定义我们的损失函数，也不必手动实现小批量随机梯度下降。\n",
        "当我们需要更复杂的模型时，高级API的优势将大大增加。\n",
        "当我们有了所有的基本组件，[**训练过程代码与我们从零开始实现时所做的非常相似**]。\n",
        "\n",
        "回顾一下：在每个迭代周期里，我们将完整遍历一次数据集（`train_data`），\n",
        "不停地从中获取一个小批量的输入和相应的标签。\n",
        "对于每一个小批量，我们会进行以下步骤:\n",
        "\n",
        "* 通过调用`net(X)`生成预测并计算损失`l`（前向传播）。\n",
        "* 通过进行反向传播来计算梯度。\n",
        "* 通过调用优化器来更新模型参数。\n",
        "\n",
        "为了更好的衡量训练效果，我们计算每个迭代周期后的损失，并打印它来监控训练过程。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1270d706",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:01:54.712705Z",
          "iopub.status.busy": "2023-08-18T07:01:54.712113Z",
          "iopub.status.idle": "2023-08-18T07:01:54.922720Z",
          "shell.execute_reply": "2023-08-18T07:01:54.921580Z"
        },
        "origin_pos": 55,
        "tab": [
          "pytorch"
        ],
        "id": "1270d706",
        "outputId": "d28ef493-878b-4445-a568-e13bd6dce720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.000248\n",
            "epoch 2, loss 0.000103\n",
            "epoch 3, loss 0.000103\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    for X, y in data_iter:\n",
        "        l = loss(net(X) ,y)\n",
        "        trainer.zero_grad()\n",
        "        l.backward()\n",
        "        trainer.step()\n",
        "    l = loss(net(features), labels)\n",
        "    print(f'epoch {epoch + 1}, loss {l:f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f52dea0",
      "metadata": {
        "origin_pos": 58,
        "id": "2f52dea0"
      },
      "source": [
        "下面我们[**比较生成数据集的真实参数和通过有限数据训练获得的模型参数**]。\n",
        "要访问参数，我们首先从`net`访问所需的层，然后读取该层的权重和偏置。\n",
        "正如在从零开始实现中一样，我们估计得到的参数与生成数据的真实参数非常接近。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa7cef5a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:01:54.927464Z",
          "iopub.status.busy": "2023-08-18T07:01:54.927072Z",
          "iopub.status.idle": "2023-08-18T07:01:54.935672Z",
          "shell.execute_reply": "2023-08-18T07:01:54.934585Z"
        },
        "origin_pos": 60,
        "tab": [
          "pytorch"
        ],
        "id": "aa7cef5a",
        "outputId": "ef840b2f-ac61-4713-c5a0-4c5eabfdec0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "w的估计误差： tensor([-0.0010, -0.0003])\n",
            "b的估计误差： tensor([-0.0003])\n"
          ]
        }
      ],
      "source": [
        "w = net[0].weight.data\n",
        "print('w的估计误差：', true_w - w.reshape(true_w.shape))\n",
        "b = net[0].bias.data\n",
        "print('b的估计误差：', true_b - b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f62d52d4",
      "metadata": {
        "origin_pos": 63,
        "id": "f62d52d4"
      },
      "source": [
        "## 小结\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6db4aa3",
      "metadata": {
        "origin_pos": 65,
        "tab": [
          "pytorch"
        ],
        "id": "b6db4aa3"
      },
      "source": [
        "* 我们可以使用PyTorch的高级API更简洁地实现模型。\n",
        "* 在PyTorch中，`data`模块提供了数据处理工具，`nn`模块定义了大量的神经网络层和常见损失函数。\n",
        "* 我们可以通过`_`结尾的方法将参数替换，从而初始化参数。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb6af2c7",
      "metadata": {
        "origin_pos": 67,
        "id": "eb6af2c7"
      },
      "source": [
        "## 练习\n",
        "\n",
        "1. 如果将小批量的总损失替换为小批量损失的平均值，需要如何更改学习率？\n",
        "1. 查看深度学习框架文档，它们提供了哪些损失函数和初始化方法？用Huber损失代替原损失，即\n",
        "    $$l(y,y') = \\begin{cases}|y-y'| -\\frac{\\sigma}{2} & \\text{ if } |y-y'| > \\sigma \\\\ \\frac{1}{2 \\sigma} (y-y')^2 & \\text{ 其它情况}\\end{cases}$$\n",
        "1. 如何访问线性回归的梯度？\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e43317d",
      "metadata": {
        "origin_pos": 69,
        "tab": [
          "pytorch"
        ],
        "id": "4e43317d"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/1781)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}